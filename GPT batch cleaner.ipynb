{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Preparing Batch File\n",
    "Batches start with a .jsonl file where each line contains the details of an individual request t"
   ],
   "id": "ef3410c4e762e627"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{\"custom_id\": \"request-1\",\n",
    " \"method\": \"POST\", \"url\": \"/v1/chat/completions\",\n",
    " \"body\": {\n",
    "     \"model\": \"gpt-3.5-turbo-0125\", \"messages\": [\n",
    "         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "         {\"role\": \"user\", \"content\": \"Hello world!\"}],\n",
    "     \"max_tokens\": 1000}}\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# upload the .jsonl Batch file",
   "id": "c9427f9c2517b8a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "batch_input_file = client.files.create(\n",
    "    file=open(\"batchinput.jsonl\", \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "print(batch_input_file)"
   ],
   "id": "b0d4e693cefede7a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Creating the Batch\n",
    "Once you've successfully uploaded your input file, you can use the input File object's ID to create a batch. In this case, let's assume the file ID is file-abc123. For now, the completion window can only be set to 24h. You can also provide custom metadata via an optional metadata parameter."
   ],
   "id": "5d4ad97aee65173f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "batch_input_file_id = batch_input_file.id\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "        \"description\": \"nightly eval job\"\n",
    "    }\n",
    ")"
   ],
   "id": "1c027d516d0f84a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "this should be the output:\n",
    "```python\n",
    "{\n",
    "  \"id\": \"batch_abc123\",\n",
    "  \"object\": \"batch\",\n",
    "  \"endpoint\": \"/v1/chat/completions\",\n",
    "  \"errors\": null,\n",
    "  \"input_file_id\": \"file-abc123\",\n",
    "  \"completion_window\": \"24h\",\n",
    "  \"status\": \"validating\",\n",
    "  \"output_file_id\": null,\n",
    "  \"error_file_id\": null,\n",
    "  \"created_at\": 1714508499,\n",
    "  \"in_progress_at\": null,\n",
    "  \"expires_at\": 1714536634,\n",
    "  \"completed_at\": null,\n",
    "  \"failed_at\": null,\n",
    "  \"expired_at\": null,\n",
    "  \"request_counts\": {\n",
    "    \"total\": 0,\n",
    "    \"completed\": 0,\n",
    "    \"failed\": 0\n",
    "  },\n",
    "  \"metadata\": null\n",
    "}\n",
    "````"
   ],
   "id": "e13746a0c1db6cc5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Checking the Status of a Batch",
   "id": "ee832483110f0adf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "batch = client.batches.retrieve(\"batch_abc123\")\n",
    "print(batch)"
   ],
   "id": "37e0a540a4ff3b35"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### status can be:\n",
    "\n",
    "Status\t        Description\n",
    "validating\t    the input file is being validated before the batch can begin\n",
    "failed\tthe     input file has failed the validation process\n",
    "in_progress\t    the input file was successfully validated and the batch is currently being run\n",
    "finalizing\t    the batch has completed and the results are being prepared\n",
    "completed\t    the batch has been completed and the results are ready\n",
    "expired\tthe     batch was not able to be completed within the 24-hour time window\n",
    "cancelling\t    the batch is being cancelled (may take up to 10 minutes)\n",
    "cancelled\t    the batch was cancelled"
   ],
   "id": "85e8bbf3a854a3bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#  Retrieving the Results\n",
    "\n",
    "Note that the output line order may not match the input line order. Instead of relying on order to process your results, use the custom_id field which will be present in each line of your output file and allow you to map requests in your input to results in your output."
   ],
   "id": "83b5e680168043c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "file_response = client.files.content(\"file-xyz123\")\n",
    "print(file_response.text)"
   ],
   "id": "e45955c0695fd6bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
